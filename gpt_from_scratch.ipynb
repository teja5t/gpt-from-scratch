{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "4WbRBQfUuRAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "block_size = 256\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embed = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "dropout = 0.2\n"
      ],
      "metadata": {
        "id": "XcM9bv-Qv--X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgHC5V0GwB2v",
        "outputId": "5ca8e258-c285-48aa-d717-6a49d42dc88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-22 06:17:18--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-07-22 06:17:18 (17.5 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx1ChM9muEuI"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in s]\n",
        "\n",
        "def decode(indices):\n",
        "    return ''.join(itos[i] for i in indices)\n",
        "\n",
        "data = torch.tensor(encode(text), dtype = torch.long)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        #compute attention\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5 #how much each letter corresponds to each other one\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float ('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embed, n_embed)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embed, n_embed),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embed, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embed)\n",
        "        self.ln1 = nn.LayerNorm(n_embed)\n",
        "        self.ln2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embed, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embed)\n",
        "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape # B is batch, T is time\n",
        "        token_emb = self.token_embedding_table(idx) # (B, T, C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C)\n",
        "        x = token_emb + pos_emb # (B, T, C)\n",
        "        x = self.blocks(x)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
        "\n",
        "        if targets == None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim = 1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "fpjS4CXruM0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d683b3-84b6-4837-b531-9f36ab785dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.6543, val loss 4.6523\n",
            "step 500: train loss 1.7673, val loss 1.8968\n",
            "step 1000: train loss 1.4353, val loss 1.6496\n",
            "step 1500: train loss 1.3114, val loss 1.5574\n",
            "step 2000: train loss 1.2278, val loss 1.5428\n",
            "step 2500: train loss 1.1622, val loss 1.5326\n",
            "step 3000: train loss 1.1039, val loss 1.5228\n",
            "step 3500: train loss 1.0462, val loss 1.5412\n",
            "step 4000: train loss 0.9917, val loss 1.5518\n",
            "step 4500: train loss 0.9336, val loss 1.5969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))\n"
      ],
      "metadata": {
        "id": "yowhIDb2uLed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dfcbe16-79de-4a3d-859c-d5ebb00373dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "AUTOLYCUS:\n",
            "Get me to you both.\n",
            "\n",
            "First Senator. Geod masterly, go, your ladies.\n",
            "\n",
            "ROMEO:\n",
            "Good morrow, forbear that I shall be\n",
            "make men.\n",
            "\n",
            "Nurse:\n",
            "You have had none, if you gaze'd with me,\n",
            "I conjoin you with my desires have done wounded\n",
            "At Richmond suppt; stands not like a chatty maid,\n",
            "For yesting 'gainst Madam Roman!'\n",
            "All-beat him that will folks, no doom,\n",
            "And stands aside, but that hath some ill river.\n",
            "\n",
            "LADY ANNE:\n",
            "O, spare us not? All to bed with all.\n",
            "\n",
            "GLOUCESTER:\n",
            "Stay, then half in tears, and beat the world;\n",
            "For whiles I cany for this truth,\n",
            "Being not toe hide our kinsman, nor now.\n",
            "\n",
            "KING HENRY VI:\n",
            "O, bram that thou, for our fortune, for caking with\n",
            "I mean to the bed savereign,\n",
            "Were should with this traitor affection's state?\n",
            "King lieu that 'tis; but that is, yet agreeing Rutland.\n",
            "Go about, Salisbury, Sir Rivea\n",
            "Mundline heart and Kent all my childred tonish\n",
            "The fillible when York well well, father tear,\n",
            "And bid him come of us a thousand news.\n",
            "\n",
            "DUKE OF MAPhaether, I'll plead thee to-night.\n",
            "I crave your gracess in clamours, let me be well.\n",
            "\n",
            "KING RICHARD II:\n",
            "Nay, let the lord.\n",
            "Marshal, John, and Montague?\n",
            "\n",
            "BUCKINGHAM:\n",
            "Faith, when at the king; this bend, in all true,\n",
            "His profanes with kind haste prisone line arm,\n",
            "Wherein am I dischoseth in loving through Clifford.\n",
            "\n",
            "NORSEO:\n",
            "Where's Caius Marcius?\n",
            "\n",
            "Messenger:\n",
            "God ye'er your honour.\n",
            "Away with your sgoverend to the languish;\n",
            "Swearn us to the greyhoundry strikes;\n",
            "Whose he has no will awaking his eyes true?\n",
            "The wring his spoilst should awe at throse him.\n",
            "The other, how we mow'd torch, it hath singulard\n",
            "Can with his eyed open my son's lord;\n",
            "Saless cannot my my success, but we are here,\n",
            "And he interports to me our fivolous\n",
            "Lief to life dargue in death\n",
            "Before this spright outy, come to thy trunk together.\n",
            "And take him hence, interreto promise me\n",
            "Either by this deity of his enemies,\n",
            "I doubt not some cease be impeachment again\n",
            "To get a severity are in either\n",
            "And time bab to peace the grander of thy country:\n",
            "Carrior O, go I know, and I have heard thee steal;\n",
            "I hope it for thy best for myself?\n",
            "Warwick, in this noble s colour what of yout,\n",
            "Not by God's lack, to that was a forlor toad.\n",
            "Your heart removed up o' both fortery only,\n",
            "With working coverts' midwing great bosoms,\n",
            "And duty move when you wash'd for here terrel:\n",
            "I give my kindor, and then have broke the slain,\n",
            "Oeh instruction, both the mighty seat,\n",
            "Stink not sto your good your queension of love;\n",
            "The loving Marge holds for Sir England!\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Yea, ailecome home to comes to London,\n",
            "Whom Warwick's hath wedlough'd homed, the fair rain,\n",
            "Who lets of comfort and Sixtlant,\n",
            "Will I forsworn our mildly hath alther York?\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Villain, farewell; my troth, old Thursday rashy,\n",
            "The Earl of Gaunt, and Gorge be gone,\n",
            "Against the proppetition of yourst--or\n",
            "I drin and knell the enforce both,\n",
            "In her Warwick's hand and in your hand,\n",
            "And die the wife is come\n",
            "With breedy outgr awrords.\n",
            "\n",
            "WARWICK:\n",
            "No, can what thou aft that stable?\n",
            "What noiles have found thy windows but an ange?\n",
            "Or, it is my father's name,\n",
            "Regoing thy wife, aband thy crown butcher murder'd,\n",
            "So much power to dry down away on the bretle:\n",
            "I were dead, death togethee of you,\n",
            "Counting fortune shall not remain may breblest;\n",
            "But in the region of waits dead,\n",
            "Thinking on common my taste o'ershamen bears,\n",
            "Along sper confidence at thy babe,\n",
            "Or, rich, methinks and temps the of sea\n",
            "At Apollo bedlance and am Autus!\n",
            "Even all thou dinto them make now.\n",
            "I not discontents; or pardon is more\n",
            "Knack'd at the house of York.\n",
            "\n",
            "Fight:\n",
            "Iw there be pleased comes still, that usurp not;\n",
            "For King Henry, go, though art thou made aside,\n",
            "To lank the heartuchio ach in the draw,\n",
            "And then been thy hand thy lips, Tybalt;\n",
            "To blood this seated shall crook for Warwick's death;\n",
            "And where enjoying thy nobing murders thy death?\n",
            "O,  O brame, that thou hast not fail this,\n",
            "For I have slow'd to hear the bringht of this side:\n",
            "You are mortal for mine is for my rage;\n",
            "But now he may, may marry, as you are kneel\n",
            "As weigh with your bed, behind I'ld not ride\n",
            "Which Cobstal yout London look with a good on!\n",
            "O, nurse, wilt thou my son and son hair,\n",
            "Nor I will stand, thy hand, departy thy while!\n",
            "\n",
            "MONTAGUE:\n",
            "Your wife, fortune can I make help of mine:\n",
            "I am not hearty, on what till usure my hand\n",
            "Return what hath young and with your suit\n",
            "Great unjustly lady wounder enemy:\n",
            "I do get her warret, and the wledge before\n",
            "Against thy lips daughter whither.\n",
            "I doubt, Hortensio, and uncles,\n",
            "Yet expect me both he shallow.\n",
            "\n",
            "GLOUCESTER:\n",
            "My Lord Hastings, go, my Lord!\n",
            "\n",
            "GLOUCESTER:\n",
            "Erry Here me, there done, Hastings,\n",
            "Accursed the swords of York; and now the rest,\n",
            "And, into a charpen's yeard, are me too lack.\n",
            "To thou body: go to-morrow;\n",
            "Yond would be he were known'd,\n",
            "And by my heart with overhour livide!\n",
            "Did now his royal silks\n",
            "Awhile you confant, comfort me to removed?\n",
            "Now, Clarence, 'tis not Henry, ben his naughty three,--\n",
            "Being but in which,--let it say too me sings--\n",
            "As pite, is himost affections as my while,\n",
            "All the cunning to be my soul\n",
            "Proclaim'd by his mother to our fool;\n",
            "On since deserts and despised,\n",
            "The grasing of whom I, Itable\n",
            "Their kinder court in proppost.\n",
            "\n",
            "POLIXENES:\n",
            "O, who's thy comidwork!\n",
            "White the queen of our dove-high death?\n",
            "O, I hope, thy mother; for thou know'st mad.\n",
            "\n",
            "GLOUCESTER:\n",
            "Not mad, he cause up it without: his royal son,\n",
            "Which you are unasky what is a pretty.\n",
            "\n",
            "CLARENCE:\n",
            "If they cannot drown be wither'd heart?\n",
            "By so I, their own grief shirt in tender time:\n",
            "My shoulder thank of blood that Biendon abide.\n",
            "I'll come to Bertonia's brother king.\n",
            "Here comes him; some more patient\n",
            "Like a hundred tender o'er servant;\n",
            "Yet Heragot's dearly to my known,\n",
            "And here the humbles shath obscury and forfeit:\n",
            "Golden send whose porce in Kate thee got.\n",
            "\n",
            "TYRRELest OVEL:\n",
            "What other might posan!\n",
            "Wortune is a courtier rebellion.\n",
            "\n",
            "KING RICHARD II:\n",
            "Madam, away! why the lady's blood,\n",
            "That of Full stainly hold a friend\n",
            "Hath painful to inferry it in the power,\n",
            "To whose grateful we fear of grief:\n",
            "Call thee draws the crown, Clarence for defendon.\n",
            "\n",
            "GLOUCESTER:\n",
            "And thou, who search-foolving good,\n",
            "Or seer tongue-stooping witties for the plain;\n",
            "Bid God above the best, was jur, and with the\n",
            "Even that wherewith Crosby to her troop.\n",
            "Here to both joy Thanksby your canopience love,\n",
            "That from Romes and Northumberland,\n",
            "Is craved and ledge sweet in York,\n",
            "What time of tongue site on uncles;\n",
            "But thou dost fid it know thy skins\n",
            "And will surely ere this covert?\n",
            "\n",
            "DUKE OF YORK:\n",
            "My lord,--\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I am advised of corserous ye.\n",
            "\n",
            "KING RICHARD II:\n",
            "\n",
            "CHRINCE\n",
            "\n",
            "DUKE OF YORK:\n",
            "How would Clarence had done the royal grace?\n",
            "\n",
            "DUKE OF YORK:\n",
            "And, in his remedies, to he hides you.\n",
            "\n",
            "DUKE OF YORK:\n",
            "My lord, I will find him sex, he so.\n",
            "\n",
            "KING RICHARD II:\n",
            "As I had, my true lifeghost, as I rather\n",
            "Unto the air?\n",
            "\n",
            "DUKE OF YORK:\n",
            "Are you contentuned to seek you on the sky\n",
            "Where I poor upon fy his heart.\n",
            "\n",
            "ESCALUS:\n",
            "The fair addeme are to me to meet thee;\n",
            "And here comes for that prosphed come straights\n",
            "Which thou speak, that'st thou not take thee these words;\n",
            "And to a clocks in all hope out yout in this muttocks.\n",
            "His heighness, for thou depart not his own?\n",
            "Why doth not brook to block the plasant rsy Fool?\n",
            "Who founder the gloriol did attains--how his hair?\n",
            "A\n",
            "ANGELO:\n",
            "Where I chance, that can ne'er woo 'twas;\n",
            "When men one bear which I pretere,\n",
            "Since past all tides\n",
            "Or Christophen accident.\n",
            "My Lord of Salisbury,\n",
            "Love Edward with your congeal'd fire and\n",
            "The orator of Duke off,\n",
            "Anon those house this share rosely artifician\n",
            "Your tribuness are but attempt and loaths.\n",
            "\n",
            "DIONE:\n",
            "O, most gentlemen! mother,\n",
            "You have protector'd my joy\n",
            "WhARD I enjoy'd with you; and your husband,\n",
            "Which I was banish'd by with your liberting.\n",
            "\n",
            "ISABELLA:\n",
            "Hail your swords? Master castions,\n",
            "Have you dedicted by ta'ken?\n",
            "\n",
            "ANGELO:\n",
            "I will tell them do good not before.\n",
            "Not any offe down too.\n",
            "\n",
            "ISABELLA:\n",
            "Montague is and all the hours so cry looks. Come,\n",
            "And meet me to me with young operts to the end.\n",
            "\n",
            "ANGELO:\n",
            "It lie down it all.\n",
            "\n",
            "LUCIO:\n",
            "And what spent you would call him joy?\n",
            "\n",
            "ISABELLA:\n",
            "Saw you, gentle my lord,\n",
            "Whom show lay the crown.\n",
            "\n",
            "LUCIO:\n",
            "Why doth have been this charge to his care?\n",
            "\n",
            "ISABELLA:\n",
            "But where he commton saves himself?\n",
            "And stand up, stand up. Good lord, stand up:\n",
            "Thou goest hereby not: but the law drinks golden\n",
            "That he Lord Henry Fifth of Alban's old.\n",
            "\n",
            "LUCENTIO:\n",
            "Thy aspectable Harry of Lancaster!\n",
            "And, thus queen in conscience;\n",
            "That you take a courte would change your dry!\n",
            "\n",
            "ESCALUS:\n",
            "For be some name, I'll at request, take it for you:\n",
            "\n",
            "That you please unto ask for in standing. Lady,\n",
            "We everly know my son-honds; and let the next\n",
            "Nor to be this fallow that question'd: thou hast made\n",
            "For Frankingham whence thy hark not becomes not\n",
            "Will along as send him I; for by the battle,\n",
            "Provost, set his generous word: more for thought,\n",
            "A little, knee, and so far I am, a\n",
            "At the helping Apolf Smotham.\n",
            "\n",
            "BRAKENSIO:\n",
            "Stay, sweet from usician why;\n",
            "I would you have laid the heartiest to begun?\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "Bague thee gone, I am not fortune:\n",
            "A phoest that looks you love down. I'll have thought:\n",
            "I not doubtion, wilt thou propp'd a,\n",
            "For to the inward we have set against me, my presensel part\n",
            "To tenderestah subjects as of joys' houses,\n",
            "Which we crown'd, were the time of proud queens:\n",
            "Shall you fly to that rough him in him,\n",
            "Yet in what we have spoke of this,\n",
            "At three once and what's done word?\n",
            "And is fit fortune base be gen to?\n",
            "\n",
            "BRAKENBURY:\n",
            "Poor son, it makes me me at yough a word,\n",
            "That I may answer yours.\n",
            "\n",
            "CLIFFORD:\n",
            "I to your honour.\n",
            "Gomb of my soul,\n",
            "And princely Rivea not in all night.\n",
            "\n",
            "RIVERS:\n",
            "Speak, gentle Richard,\n",
            "To hear my duke and misfortek how\n",
            "I drown an heart and rob.\n",
            "\n",
            "QUEEN:\n",
            "Nay, but 'tis not on Curet's, sir;\n",
            "Where galling vengeance shall should teach on:\n",
            "And your letter lives go conspiracy.\n",
            "Tells me what would be then, thou now.\n",
            "Farewell: here's thou, what they fear.\n",
            "\n",
            "RIVERS:\n",
            "Now, by Saint Paulina\n",
            "Is in Anne. Comfort will report you my hearth.\n",
            "Welcome to our bavots: if to leave your blood,\n",
            "Of royal woes that idles would not be great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "Bga5BAB8xvsa",
        "outputId": "d18378d3-9961-4434-c051-8eaa48eaead7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'generator' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-3184436569.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kRidUWnhxw7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2355b734",
        "outputId": "83a4fea3-46a8-4beb-f0a3-ee43b84870b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "print(f\"The model has {num_params} trainable parameters.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 10788929 trainable parameters.\n"
          ]
        }
      ]
    }
  ]
}